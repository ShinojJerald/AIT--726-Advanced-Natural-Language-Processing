{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjXKZ2xBiqI2"
   },
   "source": [
    "\n",
    "<img src=\"https://www2.gmu.edu/sites/all/modules/features/feature_core_theme/templates/resources/images/mason-logo.png \" alt=\"GMU Logo\" title=\"George Mason University\" />\n",
    "<hr style =\"color:#99CC99\">\n",
    "    \n",
    "<h2 style=\"font-family:Helvetica; color:#006633;\">Programming Assignment # 2</h2>\n",
    "<h3 style=\"font-family:Helvetica; color:#006633;\"> Feed-forward Neural Network for Sentiment Classification and Language Modelling</h3>\n",
    "\n",
    "<p style=\"font-family:Helvetica; font-size:1.5em;\"> \n",
    "Authors: Team 1 - Shinoj Jerald Bounaventure Kumar Jeronmary, Yitong Li, Anh Nguyen and Nina Nnamani<br>\n",
    "Course Professor: Dr. Lindi Liao <br>\n",
    "Course Name: Natural Language Processing <br>\n",
    "Course Name and Section#: AIT 726-001<br>\n",
    "University Name: George Mason University<br>\n",
    "Date: October 8, 2020    <br>\n",
    "</p>    \n",
    "<hr style =\"color:#99CC99\" width=\"75%\">\n",
    "<p style=\"font-family:Helvetica; font-size:1.4em;\"> \n",
    "Description: In this assignment, you will build feed forward neural networks for sentiment classification and language modelling. We will use the same data from Assignment 1. You will have to build the system from the scratch (e.g. numpy). Do not use any existing libraries (e.g. scikit-learn, tensorflow). \n",
    " <br>\n",
    "    \n",
    "<p style=\"font-family:Helvetica; font-size:1.4em;\"> \n",
    "Instructions: ...<br>\n",
    "\n",
    "<p style=\"font-family:Helvetica; font-size:1.2em;\"> \n",
    "1) ...<br>\n",
    "2) ... <br>\n",
    "\n",
    "<br> \n",
    "           \n",
    "<p style=\"font-family:Helvetica; font-size:1.4em;\"> \n",
    "References: The following listed sources provided some insight on code techniques that were partially adapted.\n",
    "\n",
    "Build the feed forward neural network\n",
    "https://towardsdatascience.com/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6\n",
    "    \n",
    "\n",
    " <br>\n",
    "\n",
    "<hr style =\"color:#99CC99\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVpCp83ENr7r"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QszPJ6VUNr7s"
   },
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import os\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import collections\n",
    "import re\n",
    "import numpy as np\n",
    "import time\n",
    "import xml\n",
    "import pandas as pd\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#captures runtime\n",
    "start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xd1KzhgNr7v"
   },
   "source": [
    "## Feed forward neural network for sentiment classification\n",
    "\n",
    "## Nina and Anh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEWaFBsZuaTF"
   },
   "source": [
    "### a) Create your Vocabulary: Read the complete training data word by word and create the vocabulary V for the corpus. You must not include the test set in this process. Remove any markup tags, e.g., HTML tags, from the data. Lower case capitalized words (i.e., starts with a capital letter) but not all capital words (e.g., USA). Remove all stopwords. You can use appropriate tools in nltk to stem. Stem at white space and also at each punctuation. In other words, “child’s” consists of two tokens “child and ‘s”, “home.” consists of two tokens “home” and “.”. Consider emoticons in this process. You can use an emoticon tokenizer, if you so choose. If yes, specify which one.\n",
    "\n",
    "#Nina: copy/paste and test from homework1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dIckZRSg9T_"
   },
   "source": [
    "Removes mark-up, normalizes capitalized first letter and removed emoticons/emojis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IWegsEaLg4qz"
   },
   "outputs": [],
   "source": [
    "#reading the text data\n",
    "pos_train = os.listdir(\"train/positive/\")\n",
    "neg_train = os.listdir(\"train/negative/\")\n",
    "pos_test = os.listdir(\"test/positive/\")\n",
    "neg_test = os.listdir(\"test/negative/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vzL8Owmhg4yK"
   },
   "outputs": [],
   "source": [
    "#Removing Emoticons\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\" \n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string) # no emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "E9fz4vx7g43C"
   },
   "outputs": [],
   "source": [
    "#Removing HTML tags\n",
    "def remove_tags(text):\n",
    "    s = re.sub(r'<[^>]+>', '', text)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxppwxsphD8b"
   },
   "source": [
    "Creates vocabulary by incorporating function and tokenizing text for unstemmed and extract features for Bag of Words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9umrlASThG2q"
   },
   "outputs": [],
   "source": [
    "# Cleaning and adding the data\n",
    "def create_list(dir,type,type1):\n",
    "    return_list=[]\n",
    "    for i in range(0, 500):\n",
    "        file1 = open(type+\"/\"+type1+\"/\" + dir[i])\n",
    "        try:\n",
    "            text = file1.read()\n",
    "            text = remove_tags(text)\n",
    "            text = remove_emoji(text)\n",
    "            return_list.append(text)\n",
    "        except UnicodeDecodeError:\n",
    "            k=0\n",
    "        file1.close()\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "T9fH21sihG5y"
   },
   "outputs": [],
   "source": [
    "#Creating dataframe with positive and negative tweets\n",
    "def createDataFrame(pos_train_list,neg_train_list):\n",
    "    df1 = pd.DataFrame(neg_train_list)\n",
    "    target2 = [0] * len(neg_train_list)\n",
    "    df1[\"target\"] = target2\n",
    "    df1 = df1.rename(columns={0: \"text\"})\n",
    "#Giving positive tweets as 1 and negative tweets as 0\n",
    "    df = pd.DataFrame(pos_train_list)\n",
    "    target1 = [1] * len(pos_train_list)\n",
    "    df[\"target\"] = target1\n",
    "    df = df.rename(columns={0: \"text\"})\n",
    "    \n",
    "#Data is getting shuffled here\n",
    "    data = pd.concat([df, df1])\n",
    "    #data = data.sample(frac=1)\n",
    "    x = list(data[\"text\"])\n",
    "    y=np.array(data[\"target\"])\n",
    "\n",
    "    return x,y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "njeAV-zmhK43"
   },
   "outputs": [],
   "source": [
    "# Tokenizing the text\n",
    "def clean(text):\n",
    "\n",
    "    vocab=[]\n",
    "    for j in word_tokenize(text):\n",
    "        if (j != ''):\n",
    "            if not j.islower() and not j.isupper():\n",
    "                j = j.lower()\n",
    "            vocab.append(j)\n",
    "\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gA9-cZk-DtK-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5c7uS5q1Nr8W"
   },
   "outputs": [],
   "source": [
    "# Tokenizing the text and stemming it\n",
    "def cleaningStemmed(text):\n",
    "\n",
    "    ps = PorterStemmer()\n",
    "    vocabulary_stemmed=[]\n",
    "    for j in word_tokenize(text):\n",
    "        if (j != ''):\n",
    "            if not j.islower() and not j.isupper():\n",
    "                j = j.lower()\n",
    "            vocabulary_stemmed.append(ps.stem(j))\n",
    "\n",
    "    return vocabulary_stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqcVeId1hTBj"
   },
   "source": [
    "Combine functions\n",
    "- load in the data\n",
    "- create list\n",
    "- make dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "HcDv6D1ZhG88"
   },
   "outputs": [],
   "source": [
    "#Combine functions to load training set \n",
    "pos_train_list = create_list(pos_train,\"train\", \"positive\")\n",
    "neg_train_list = create_list(neg_train,\"train\", \"negative\")\n",
    "X,y=createDataFrame(pos_train_list,neg_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "hf36MZc7hd2p",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@SouthwestAir I would appreciate that.  Thank you.\\n',\n",
       " '@USAirways thank you very much.\\n',\n",
       " \"@JetBlue I'm all set. About to fly. Not bad for a first date with a giant metal bird machine. She even brought snacks.\\n\",\n",
       " '@SouthwestAir I got a flight at 11:55am on Thursday but looking for something tomorrow anything available?\\n',\n",
       " \"@AmericanAir you're my early frontrunner for best airline! #oscars2016\\n\",\n",
       " '@SouthwestAir #RedCarpet Southwest Companion Pass would be great!\\n',\n",
       " \"@USAirways @AmericanAir major issues getting out of Boston but your crew has been exceptional. Let's see how things roll out in Philly.\\n\",\n",
       " '@JetBlue thanks. I appreciate your prompt response.\\n',\n",
       " '@united such a relaxing space for a drink before my flight! (at @United Global First Lounge) https://t.co/j4cj0lrF2d http://t.co/dTLGUQ1kAk\\n',\n",
       " '@united ok. I just submitted. Thanks for the opportunity to give feedback.\\n',\n",
       " '@united thank you\\n',\n",
       " \"@SouthwestAir was fantastic! That's the best flight service I've ever had.\\n\",\n",
       " '@AmericanAir ok I just received an email with my registration from your team. Thanks a lot\\n',\n",
       " '@AmericanAir This is exactly why ill be flying AA from @Dulles_Airport to Dallas! Only airline I trust!\\n',\n",
       " '@USAirways your team member at DCA- Tamara R. is her name was awesome. You should have more employees like her!\\n',\n",
       " '@AmericanAir got back eventually! Was a rollercoaster. Once I got to the airport &amp; got to speak to someone things got fixed very quick.\\n',\n",
       " '@united Thanks so much  my passport was recovered\\n',\n",
       " '@AmericanAir Thanks!\\n',\n",
       " '@JetBlue Thank you for the free flyfi!! Makes an already great airline even better! #jetblue #Boston #westpalmbeach #flybetter\\n',\n",
       " '@VirginAmerica Thanks so much for the awesome support you guys rock!\\n',\n",
       " '@SouthwestAir @love_dragonss oh my god LAUREN OH MY GOD OH MY GOD\\n',\n",
       " '@VirginAmerica your inflight team makes the experience #amazing!\\n',\n",
       " '@AmericanAir Understood. Thanks anyway\\n',\n",
       " '@AmericanAir Thanx for replying. DM sent\\n',\n",
       " '@united thank you! Good service safe flight... 1/2 way home!\\n',\n",
       " \"@JetBlue 's free wifi on board is the best thing that's happened since sliced bread\\n\",\n",
       " '@united thanks\\n',\n",
       " '@JetBlue will call. Thank you!\\n',\n",
       " '@AmericanAir  TPA - ORD!!! AA1679 Another successful journey thanks for the hospitality!\\n',\n",
       " '@united Big thanks to Ms. Winston for assisting me over the phone with a baggage claim issue today. She really went the extra mile!\\n',\n",
       " '@united Hmmm...seems like this could be something to be changed to be more #flyerfriendly.\\n',\n",
       " '@VirginAmerica Like http://t.co/VPqEm31XUQ\\n',\n",
       " '@united good job at CLE .. TPA on schedule ... 4 to 5 inches of snow ! http://t.co/9tbsJquw41\\n',\n",
       " '@JetBlue @Leopolds_IC  No but my friend in the picture - Phillip Heller (JFK IFC) did and he said it was delicious!\\n',\n",
       " \"@united Thanks to Karen Salisbury at IAH for amazing customer service!  Found my daughter's bag lost on UA1516.  Made her day!\\n\",\n",
       " '@AmericanAir Flight 236 was great. Fantastic cabin crew. A+ landing. #thankyou #JFK http://t.co/dRW08djHAI\\n',\n",
       " '@SouthwestAir thank you for always going above and beyond with your customer service!!!!!! #favoriteairline #luvforSW #southwestAir\\n',\n",
       " '@usairways Thanks to Kevin and team at F38ish at PHL for some great service recovery tonight. Appreciate it.\\n',\n",
       " '@USAirways   Just talked to reservation. Must congratulation to them. Very friendly.  Good for usair. The ONLY airline we fly.\\n',\n",
       " \"@SouthwestAir you're the best\\n\",\n",
       " '@SouthwestAir listening center is open seating just like on their planes. #RaganDisney\\n',\n",
       " '@united awesome. Thx. And thx for replying so damn fast sure as hell beats 80s cheeze hold music!!\\n',\n",
       " \"@AmericanAir I don't think you should help him at all based on his behavior. The voucher and cot seem like enough lol ðŸ˜ƒ\\n\",\n",
       " '@SouthwestAir I wanted to thank the great efforts of Jamie McKinnie in BUF she is a true pro! during major delays she was owning it! #raise\\n',\n",
       " '@USAirways Thanks guys! Got hold of someone. Really awesome service I appreciate it :)\\n',\n",
       " \"@eatgregeat WOW~Thx for thinking of us Greg! Heard #SOBEWFF was amazing! We've heard the same about @JetBlue (ps thx for the info) #TeamNKH\\n\",\n",
       " '@VirginAmerica wow this just blew my mind\\n',\n",
       " \"@SouthwestAir tv stream means I get to spend my flight watching 1999 and 2011 Women's World Cup Finals. #throwback #bestflightever\\n\",\n",
       " '@JetBlue thanks for the info. Already doing it now before we board! Looking forward to the future upgrades! #JetBlue http://t.co/5Db9eSBNzG\\n',\n",
       " \"@SouthwestAir thanks for your attention I've been flying southwest for 3 years and haven't had this issue in the past.\\n\",\n",
       " '@JetBlue @roxydigital HAHA. you didnâ€™t disappoint. Well done. #JVMChat\\n',\n",
       " '@united counter agents at RDU deserve a medal. #thankyou\\n',\n",
       " \"@JetBlue thanks for listening. Doesn't mean I don't appreciate you!\\n\",\n",
       " '@JetBlue I agree!!!  If only there was a frequent tweeter discount so I could fly to see more friends! ðŸ˜€@Tinman2IronMan @meggersrocks\\n',\n",
       " '@united Terrific. Many thanks. Looking forward to being back on UA tomorrow. Had a great flight up to Vancouver.\\n',\n",
       " '@AmericanAir #AATeam thanks for working in very rigorous weather conditions for all\\n',\n",
       " '@JetBlue got it. thanks the quick reply.\\n',\n",
       " \"@USAirways First class service on US 769 PHL-MCO today from the flight attendant in F. I didn't catch her name but she was top notch!\\n\",\n",
       " '@SouthwestAir JH thank you. I finally got through the second time.\\n',\n",
       " \"@united thanks ... not sure arranged move to the earlier flight but I'm at the gate with a seat assignment.  Super nice agent at gate C4 ORD\\n\",\n",
       " \"@united thanks for moving my dad on to my my mom's flight. You helped make his birthday start with #FriendlyFriday Awesomeness! 4 paws up!\\n\",\n",
       " '@AmericanAir thank you!\\n',\n",
       " '@united Resolved. Over hour of work on  ground &amp; somehow the system reset itself during takeoff. I appreciate the quick response/service.\\n',\n",
       " '@AmericanAir Thank you for the quick customer service today. #RefundProcedureNotTooPainful I know that Winter Weather is not your fault.\\n',\n",
       " '@VirginAmerica and again! Another rep kicked butt! Naelah represents your team so beautifully!! Thank you!!!\\n',\n",
       " \"@SouthwestAir Thanks for replying I sen't my conf #! I love aviation and Southwest and all I wanted for my 18th was to fly SWA for the day!\\n\",\n",
       " '@AmericanAir fantastic thanks! Will try and tweet a photo of the view :)\\n',\n",
       " '@JetBlue thanks! Have a good Sunday.\\n',\n",
       " '@united So far so good. Just stepped down in Denver. Next Stop Portland!\\n',\n",
       " '@JetBlue I would prefer a similar picture but full of E190 tails but great shot!\\n',\n",
       " '@USAirways Haha - that will indeed be a great day!\\n',\n",
       " '@USAirways Flight # 604. Thanks.\\n',\n",
       " \"@SouthwestAir All's well. I got comped with multiple other bags which just made my day! http://t.co/1AAVvoREpH\\n\",\n",
       " '@united enjoyed #heathrow lounge so much i almost missed my @airnzusa flight!\\n',\n",
       " '@JetBlue ok thanks. Safety first.\\n',\n",
       " '@americanair Greatest Newark Gate Agents ever: David Deane Norma Sedholm and Luz Calderon just made me feel like a king. #AmericanAirlines\\n',\n",
       " '@SouthwestAir knows whats up! That #BlackHistoryMonth commercial. Just another thing to add to reasons why I fly with #SouthWestAirlines\\n',\n",
       " '@united thanks\\n',\n",
       " '@USAirways you can thank supervisor Jeanine and her coworkers for the excellent customer service they provided\\n',\n",
       " '@USAirways Your CLT baggage crew deserves a #kudos. I had to run to make my connection. And my bags still made it! #CustomerService\\n',\n",
       " '@SouthwestAir Thanks. 436. Only a minor delay so not a big deal. :)Appreciate the concern though. Boarding now. You do have amazing service!\\n',\n",
       " '@JetBlue haha. TY. Do you know what time that lane opens at Logan?\\n',\n",
       " '@united EWR agent Barbara was FABULOUS and an example of CUST. SERV. A pleasure talking to youðŸ˜Š http://t.co/KMQuLY9g5E\\n',\n",
       " '@united Rhonda C. at Atlanta airport redeemed you guys. She got us straightened out.\\n',\n",
       " \"@VirginAmerica gave a credit for my Late Flight flight yesterday. Great service !!!! That's a Wow moment! Unexpected gesture!\\n\",\n",
       " '@VirginAmerica thank you\\n',\n",
       " '@AmericanAir keep up the good work.  Got me to my destination safe and on time today\\n',\n",
       " '@USAirways yes I did thank you! They did a great job turning the flight in jan !\\n',\n",
       " '@SouthwestAir I just received your birthday card.  It was amazing and made me smile with joy.  Nice videos.  Thanks.\\n',\n",
       " '@SouthwestAir oh my gosh! Going to dm you now! Thank you!\\n',\n",
       " \"@JetBlue @FerrisSalameh Love JetBlue's speedy Twitter customer service.\\n\",\n",
       " \"@VirginAmerica not worried it's been a great ride in a new plane with great crew. All airlines should be like this.\\n\",\n",
       " '@JetBlue thanks for letting us know. Hoping for no more delays!\\n',\n",
       " '@united you guys continue to impress me in Houston. http://t.co/cIh1qNllcM\\n',\n",
       " '@united Leaving soon. Thanks!\\n',\n",
       " '@SouthwestAir save mile to visit family in 2015 and this will impact how many times I can see my mother.  I planned and you change the rules\\n',\n",
       " '@united I trust you enough to put my coat in my checked bag!\\n',\n",
       " '@SouthwestAir thx. Make it right. Help Meagan Fouty Brancato fl#2771 dfw gate 4 preboard w/kids - b4 group A please. Please.\\n',\n",
       " '@JetBlue friendly engaging personable handled clarifying questions about baggage fees well and took an interest in what I was doing.\\n',\n",
       " '.@united Thanks. Hopefully this is easily resolved.\\n',\n",
       " '@SouthwestAir thanks to Ella-Mae at LAS counter for going above and beyond to help us get back to ABQ after our flight was Cancelled Flightled!\\n',\n",
       " '@VirginAmerica thanks so much!\\n',\n",
       " \"@JetBlue awe you guys are great can't wait to travel with you again soon!!!\\n\",\n",
       " \"@JetBlue Really!? That's good to hear! Thanks for the update @walls29 We may make that business meeting after all.\\n\",\n",
       " '@JetBlue I flew to San Francisco from Fort Lauderdale with you last year had a fantastic time so would like to go back !\\n',\n",
       " '@JetBlue okay awesome! Thank you!\\n',\n",
       " '@united Thanks!\\n',\n",
       " \"@SouthwestAir That would be great. Thank you! I'll send it over when you follow.\\n\",\n",
       " \"@AmericanAir excellent!  Love you guys!  If it is first class I'll hug ya'll!  See you shortly!\\n\",\n",
       " '@united the staff was rather efficient and got us solutions just freaked me out a little being in limbo in the air.\\n',\n",
       " '@JetBlue Will do. Thanks!\\n',\n",
       " \"@USAirways thanks for slowing the inbound plane down so that we didn't need to worry about 4438 EYW being Late Flight. Great holz ahead. Cheers! ðŸ˜€\\n\",\n",
       " \"@VirginAmerica For my Grandma Ella's 80th she would &lt;3 a bday greeting from your flight crew! She was a stewardess for Eastern Airlines.\\n\",\n",
       " '@USAirways Absolutely!! The staff was amazing!!\\n',\n",
       " '@JetBlue Great thank you!\\n',\n",
       " '@united Thanks for explanation. It seems like an odd incentive structure tho because it dramatically diminishes the value of the certs.\\n',\n",
       " \"@JetBlue I can't say what airline I am on right now but I sincerely miss you. #bestairline\\n\",\n",
       " \"@USAirways Exicted to be flying with y'all soon !!\\n\",\n",
       " '@AmericanAir why thank you!! Yayayay!!\\n',\n",
       " '@VirginAmerica hahaha ðŸ˜‚@VirginAmerica YOU GUYS ARE AMAZING. I LOVE YOU GUYS!!!ðŸ’—\\n',\n",
       " '@united : thanks! i will catch my conection! :)\\n',\n",
       " 'What can I say other than when it comes to my #BrandLoveAffair w/ @jetblue ur my #soulandinspiration https://t.co/IGkoGyWksr #umosaicmecrazy\\n',\n",
       " '@JetBlue beautiful ride. Thanks again:)\\n',\n",
       " '@AmericanAir I wish I could remember all of their names!\\n',\n",
       " '@JetBlue shows us their sense of humor with these tongue-in-cheek flight etiquette videos: http://t.co/GGuAA1JvDF\\n',\n",
       " \"@SouthwestAir That's an awesome library.\\n\",\n",
       " \"@SouthwestAir yeah haha. Never been in one. It's expensive ðŸ˜‚ðŸ˜‚ and we will!!!!! So much fun! #destinationdragons\\n\",\n",
       " '@JetBlue Thanks so much for talking to me! The article about #Twitter chats came out great! http://t.co/rKorHvR9z1 #contentmarketing\\n',\n",
       " '@SouthwestAir  Your Terry is our hero! Got my husband back thru security to retrieve cellphone left on plane in Austin. Terry #85832 U Rock!\\n',\n",
       " '@AmericanAir pretty impressed with the in flight entertainment. Full touch usable smooth good selection.\\n',\n",
       " '@JetBlue Thanks. Used phone instead of computer and it worked!! Thx again!\\n',\n",
       " \"@JetBlue @EllaHenderson omg!  Wish I had a flight today!  Haha there's always next time!  Have fun at #LFT5\\n\",\n",
       " '@USAirways your ticket agents at gate 4 in Providence airport rocked tonight especially Kristy sorry if that is not the correct spelling.\\n',\n",
       " '@JetBlue why yes yes it does!!!!  Great trip down!! Thanks for the lift!!!!\\n',\n",
       " '@united perfect! Thank you!\\n',\n",
       " '@USAirways They were breathing very heavily. but were super helpful. Thank you.\\n',\n",
       " '@SouthwestAir sign me up!\\n',\n",
       " '@VirginAmerica I donâ€™t use Passbook =/ I still love you though &lt;3 :) Iâ€™ll just use my email in the future.\\n',\n",
       " '@AmericanAir Karen Riedel is a rock star employee and a miracle worker.  I really appreciated her help this morning!\\n',\n",
       " '@USAirways On re-accommodation number Lisa (Liza?) in Raleigh was very helpful\\n',\n",
       " '@JetBlue last sleep in Cali... back to JFK tomorrow night.  Looking forward to an another amazing flight with you all :)\\n',\n",
       " '@united thanks gate agent extraordinaire Seau Fong for helping me get re-booked out of Boise and (hopefully) home to NYC sometime tonight!\\n',\n",
       " '@VirginAmerica Only way to fly! #Elevate #Gold\\n',\n",
       " '@united great flight into PVD. Smallest plane I have ever been on and smoothest landing ever!\\n',\n",
       " '@JetBlue @AmericanAir ah ha! I misread the end date as being 2014 not 2015. Thanks for clarifying :)\\n',\n",
       " '@united Please send me the link/email to formally compliment Irene in SLC on some of the best customer service ever. #PaxEx\\n',\n",
       " '@SouthwestAir @PaytonTaylor129 I love Southwest and Payton Taylor!\\n',\n",
       " '@united it was such a lovely part of this long day - attendants on UA5168 (most) /UA795 were beyond exceptional today. #GiveThoseLadiesRaise\\n',\n",
       " '@USAirways ok thanks\\n',\n",
       " '@USAirways shout out to the pilots and FC attendant(Eliz) of US 673. Super strong crosswinds during landing. Eliz did a super job throughout\\n',\n",
       " '@SouthwestAir love them! Always get the best deals!\\n',\n",
       " \"@united Very impressed so far. An app that's worth a damn and sms updates on my flight.\\n\",\n",
       " '@united. You guys made my day. Treated me well. Thank you!!!\\n',\n",
       " '@SouthwestAir thank you for great customer service. Trying to make it to San Antonio and your staff and alerts have been helpful. Boo ice!\\n',\n",
       " '@SouthwestAir @JohnWayneAir Thank you both very much!!\\n',\n",
       " \"@JetBlue Although it wasn't totally the answer I was looking for I appreciate the prompt response.\\n\",\n",
       " \"@SouthwestAir Thanks for making good on @PoteetTJ 's Cancelled Flightled flight.\\n\",\n",
       " '@JetBlue Awesome! #bestairlineever\\n',\n",
       " '@united you too!\\n',\n",
       " '@SouthwestAir Thanks for the response. Was able to get my situation resolved. Not a fan of Mother Nature today. :)\\n',\n",
       " \"@JetBlue toss this ticket...it's great PR and I'm sure every college student following me will be willing to rock out wit too ðŸ‘€ðŸ‘€\\n\",\n",
       " '@AmericanAir @dfwairport Guys let it go. http://t.co/vOxcghciJi\\n',\n",
       " '@SouthwestAir constantly providing wonderful views and service! #SouthwestLuv http://t.co/9UNxqOTzIK\\n',\n",
       " '@VirginAmerica @SSal thanks!\\n',\n",
       " \"@AmericanAir I tried that. They won't book us with another airline. I wish I had flown with you! We are now stuck in FL til Weds.\\n\",\n",
       " '@AmericanAir appreciate update. Have also appreciated our pilots effort to explain to us just now. Accurate authoritative comms is vital.\\n',\n",
       " '@AmericanAir He thanks you. Anything you can do to help. Would any further information help in the process?\\n',\n",
       " '@united 732 from Denver. We just boarded! Fingers crossed we get into the air!!!\\n',\n",
       " '@SouthwestAir great example of customer service this morning at MSY headed to ATL. Alison and Bobbi were fantastic! Gate B8. Thank you.\\n',\n",
       " '@VirginAmerica your beautiful front-end design is down right now; but it was cool to still book my ticket b/c all your back-end was secure.\\n',\n",
       " '@SouthwestAir FINALLY!  A Passbook option for the SWA App. Thank you!!!!!\\n',\n",
       " \"Thanks! Hope I don't look like a complainer I've written of good experiences w/you in the past and am making do in terminal 5 :) @JetBlue\\n\",\n",
       " '@AmericanAir Yes thank you. Just not how I wanted to start my vacation!\\n',\n",
       " \"@JetBlue Thanks for taking me back home today despite Pandora's best efforts to Cancelled Flight the flight. #jetblue #backhome #noplacelikehome\\n\",\n",
       " '@SouthwestAir you guys are so clever ðŸ˜ƒ http://t.co/qn5odUGFqK\\n',\n",
       " '@SouthwestAir love the passbook update. Used it the day after it was released. Finally!! Thank you!\\n',\n",
       " '@united JT thanks for your help Iâ€™ll complete the form once we are back home\\n',\n",
       " \"@united well it IS John Hughes' birthday. But I will stick w the plane &amp; hold off on trains &amp; automobiles. Gate workers are doing well.\\n\",\n",
       " 'Not your fault @JetBlue Social Media Awesome People. I know everyone is working hard to get us in our way.\\n',\n",
       " '@JetBlue Counting on your flight 989 to get to DC!\\n',\n",
       " '@united @suntoshi I still like you united airlines\\n',\n",
       " '@AmericanAir @beantownmatty Sounds like a date!\\n',\n",
       " '@SouthwestAir SEA to DEN. South Sound Volleyball team on its way! http://t.co/tN5cXCld6M\\n',\n",
       " '@united I will. Thanks.\\n',\n",
       " \"@united just confirmed a seat! Crisis averted! Beers won't be missed now\\n\",\n",
       " '@united Hubby made it by the skin of his teeth!   :)\\n',\n",
       " '@united thank you.\\n',\n",
       " \"@USAirways that's where we are now. Thank you.\\n\",\n",
       " '@united New Apple crÃ¢pe amazing! Live from UA1207. Really nice crew too.  #AmericanAir has biscuits UA needs them 2 http://t.co/gZ9GqDT7Jj\\n',\n",
       " '@USAirways â€” I had exceptional service on flight #403 from IND to PHX!!\\n',\n",
       " '@SouthwestAir though I work for another major airline  I LOVE your Black history month commercial. I Thank you.\\n',\n",
       " '@SouthwestAir Sent your way thanks for the help.\\n',\n",
       " \"@SouthwestAir I wish i would've seen this 4 hours ago!!! I WANTED TO SEE THEM TONIGHT SO BAD!!!! #CRYING\\n\",\n",
       " '@USAirways thanks so much!\\n',\n",
       " '@JetBlue I like \" Follow @JetBlue \"\\n',\n",
       " '@JetBlue you found my camera!  Thank you!  You rock!\\n',\n",
       " '@united Made the upgrade list. Will fly 1st tomorrow (for 40 min) for the first time ever! ðŸ™Œ #StatusMatchPaidOff http://t.co/ATfRKp6goY\\n',\n",
       " 'Kudos well deserved! Just wish the rest of my @JetBlue experience today measured up to their example!\\n',\n",
       " '@JetBlue you got yourselves hot ladies flying the air for life #loyal\\n',\n",
       " '@AmericanAir thank you for the update!\\n',\n",
       " '@USAirways Thx to gate agt John Pascucci for finding us a flight from CLT to PVD after our original one was Cancelled Flightled http://t.co/YiwLhQhZgp\\n',\n",
       " \"@JetBlue Crisis averted! Flight #69 from BOS to FLL is boarding. Let's hope the new pilots aren't Clarence Oveur and Roger Murdock. :-)\\n\",\n",
       " '@USAirways Mellani B. and whole team in Columbia SC are absolute superstars. Incredibly helpful.\\n',\n",
       " '@SouthwestAir thank you :-)\\n',\n",
       " '@JetBlue thank you. Just sent msg.\\n',\n",
       " '@USAirways #tbt every day.\\n',\n",
       " '@JetBlue Seems very likely.\\n',\n",
       " '@AmericanAir Awesome customer service on #390 from rdu. They snuck my wife a warm cookie. Thx!\\n',\n",
       " '@SouthwestAir thank you. Great customer service so far. Accidents happen I understand. Hopefully everything works out.\\n',\n",
       " '@SouthwestAir Thanks so much!\\n',\n",
       " '@JetBlue Love you guys sooooooo much. Ridiculously appreciated! A+ service!\\n',\n",
       " '@SouthwestAir really easy for locals to get down to the strip. book.\\n',\n",
       " \"@AmericanAir everything's good now brothaaaaaa\\n\",\n",
       " '@SouthwestAir Kudos for adding #Passbook to your app! I LOVE IT!\\n',\n",
       " '@USAirways No Problem - he was the only person in the airport who would help :)\\n',\n",
       " '@united I just received notification of in-flight Wi-Fi for UA863 from @flySFO to @SydneyAirport. Amazing!\\n',\n",
       " '@SouthwestAir THANK YOU SO MUCH!! http://t.co/tGSB1DfPS3\\n',\n",
       " 'Cc @DadBoner  #boldflavors â€œ@united: Weâ€™re bringing Bourbon St. to 35000 ft. with bold flavors fresh ingredients and more dining options\"\\n',\n",
       " '@AmericanAir thanks me too\\n',\n",
       " '@SouthwestAir Way to go flying out of Denver today! Must be the only airline not Cancelled Flighting/delaying flights! #FlySWA #denverairport\\n',\n",
       " '@AmericanAir Yes thanks for checking. Very cramped but got on &amp; made it safely. Flying back tomorrow at 1pm. http://t.co/CSddCCMvbD\\n',\n",
       " '@united I am - thank you!\\n',\n",
       " '@JetBlue good morning sunshine! #TailfinThursday http://t.co/Nc0ES6e4Lf\\n',\n",
       " '@JetBlue Great thanks\\n',\n",
       " '@JetBlue Mark T.  in Austin was great handling my bag issue.  #thanks\\n',\n",
       " '@SouthwestAir rules.\\n',\n",
       " '@JetBlue love traveling with Jetblue. Cant wait to go to Paris oui oui!!! NYC was awesomeee!\\n',\n",
       " '@JetBlue Success! Good work JetBlue team\\n',\n",
       " '@AmericanAir Thanks! Are they really open 3.30 am - 7 pm every day? Any way to check they are open before going all the way there? Thanks.\\n',\n",
       " '@united thank you. I flew into Newark from Vail/Eagle.\\n',\n",
       " '@JetBlue you bet:)\\n',\n",
       " '@USAirways thanks for the reply hoping everything is cleared up in Charlotte by Monday\\n',\n",
       " \"@united flight ua3576 gate b1. And tell ray I somehow made it on to the 736 flight out of IAH and didn't have to wait for the 917 one. :)\\n\",\n",
       " '@VirginAmerica OMG FINALLY\\n',\n",
       " '@united thnx!\\n',\n",
       " '@JetBlue Finally taking off! LAS-FLL-SJU #letsgo\\n',\n",
       " '@JetBlue btw her name was Samantha and she won over everyone on the flight\\n',\n",
       " \"@AmericanAir I'm great thanks keep up the good work\\n\",\n",
       " '@JetBlue Hopefully now my application for JetBlue donut designer will finally go through the proper channels.\\n',\n",
       " '@AmericanAir Chicago seen from seat 6A AA 1620. So far a great ride! On to PDX! http://t.co/X4rsvAGIjN\\n',\n",
       " '@SouthwestAir Love Southwest. You guys have been good to me! http://t.co/X4tDY84dBH\\n',\n",
       " '@SouthwestAir Thanks for the info! Have a good day.\\n',\n",
       " '@SouthwestAir not frustrated just an idea! Great crew. Thanks! #happycustomer\\n',\n",
       " \"@AmericanAir no space in my seat but thanks to your pilots I'm back 25mn early to Ohare!! Didn't think that was possible!! #sna2ord #1644\\n\",\n",
       " '@SouthwestAir Already signed up!  Thanks!  Looking forward to trying the Southwest experience.\\n',\n",
       " '@jetblue #philly lost and read program - Our customers get hot tea great crewmembers top notch info &amp; now #BOOKS! http://t.co/9rAGncw2Bk\\n',\n",
       " '@SouthwestAir LUV! your new Luv Television Commercials. Traveled on your airline last year return trip from NYC...#feltthelove\\n',\n",
       " '@united of course not. The inflight crew was great!\\n',\n",
       " '@SouthwestAir thanks connection thru Nashville have A1 boarding pass get to Dallas gate boarding 40 min before flt get end of B group\\n',\n",
       " '@JetBlue ðŸ˜\\xadðŸ˜\\xadðŸ˜\\xadðŸ˜\\xad yall are really better then American Airlines though.\\n',\n",
       " '@united thanks for the upgrade today great way to start my week! Cc: @CiscoJimFrench @cobedien\\n',\n",
       " '@AmericanAir Aww Thanks AA..DFW was on GMA up here this AM..so i understand ..Btw A.A is my Airline when im able to trv..Love you guys.:)\\n',\n",
       " '@AmericanAir thanks so much!\\n',\n",
       " '@united thank you. Been trying for two days to set this up.\\n',\n",
       " '@AmericanAir yes called your UK number on skypeâ€¦well worth the $.50.  i recommend others do the same.\\n',\n",
       " '@SouthwestAir Thank you SWA and Shannon G. @LASairport (C22) for being a miracle worker! #awesome\\n',\n",
       " \"@VirginAmerica plus you've added commercials to the experience... tacky.\\n\",\n",
       " '@USAirways thanks to the gate agent in State College PA that was able to get me on an earlier flight AND figure out an earlier connection!\\n',\n",
       " '@SouthwestAir your flight attendants are really funny!! The sass is giving me life!!! ðŸ˜‚\\n',\n",
       " 'Keep it up :) @AmericanAir\\n',\n",
       " '@JetBlue thanks. I will use the extra time to do some more shopping! Did somebody say duty free?\\n',\n",
       " \"@JetBlue's CEO battles to appease passengers and Wall Street - http://t.co/uy28D1UEgX http://t.co/vJFV7KSGcQ\\n\",\n",
       " '@JetBlue safety first !! #lovejetblue\\n',\n",
       " '@SouthwestAir Just watched crew on flight 380 help elderly lady off plane...#firstclass\\n',\n",
       " '@VirginAmerica Flying LAX to SFO and after looking at the awesome movie lineup I actually wish I was on a long haul.\\n',\n",
       " '@united thanx so much. You followed through and emailed me a $1000 ticket voucher. #unitedairlines they do care\\n',\n",
       " '@united @annricord Great! Appreciate itðŸ˜Š\\n',\n",
       " '@USAirways great thank you!\\n',\n",
       " '@VirginAmerica Moodlighting is the only way to fly! Best experience EVER! Cool and calming. ðŸ’œâœˆ #MoodlitMonday\\n',\n",
       " '@AmericanAir thanks for responding ... will do!\\n',\n",
       " '@united The only thing you fella have done right today is get me to the pacific time zone.\\n',\n",
       " \".@AmericanAir @TyWinter it's really the small things--the details--that make an excellent experience or a really irritating one.\\n\",\n",
       " '@SouthwestAir ok thank you  i hope  so too\\n',\n",
       " '@JetBlue:  Ahoy from a loyal #AllYouCanJetPass holder! When do you anticipate direct US flights to #Havana #Cuba? (#JetBlue #Vacation)\\n',\n",
       " \"@AmericanAir ok no worries. Thanks for the straight story. It's appreciated.\\n\",\n",
       " \"@SouthwestAir have to be honest didn't expect a fast response thank you!  Off to #Chiberia we go!\\n\",\n",
       " \"@AmericanAir all good! I'm catching the 11:10p flight tonight. Thanks for the response.\\n\",\n",
       " '@JetBlue oh yes! I hope you expand to other airports soon so I can fly you to see my family each year!!!!\\n',\n",
       " '@united thank you for getting our daughter home when @americanair Cancelled Flightled all their flights to Nashville\\n',\n",
       " 'Nice RT @VirginAmerica: The man of steel might be faster but we have WiFi â€“ just saying. #ScienceBehindTheExperience http://t.co/FGRbpAZSiX\\n',\n",
       " '@SouthwestAir One heck of an airline http://t.co/CyoOnZfTdC\\n',\n",
       " '@USAirways Best GAgent in a long time - Danny B. for US628 DFW-CLT. Appreciated how up to date he kept us during irrops. Super professional!\\n',\n",
       " '@SouthwestAir Awesome!!! Sending now.\\n',\n",
       " \"@united thanks -- we filled it out. How's our luck with this? Is it common?\\n\",\n",
       " '@SouthwestAir I got it added thank you! :)\\n',\n",
       " \"@AmericanAir thank you for quick responses.   #aa usually has fantastic customer service. That's why I was so shocked when it wasn't there\\n\",\n",
       " \"@USAirways good work by flight 1798 crew.  #Chairman's recognition even in coach.  Too many #missedupgrades Late Flightly.  What's up with this?\\n\",\n",
       " '@JetBlue thanks for update http://t.co/K7uBOTMr1r\\n',\n",
       " '@united thanks for prompt response.  Another hour to enjoy vacation! Perhaps a bug in the app as it still shows 2:55.\\n',\n",
       " \"@AmericanAir @USAirways Statement wasn't sent yesterday like Jeanine said. After I even called last night as well. Again excellent service\\n\",\n",
       " '@USAirways Another great flight #FunFlightAttendants. Thanks for showing my dad wonderful customer service. #flt635 #LAX #PHX #SundayFunday\\n',\n",
       " '@JetBlue you guys rock!\\n',\n",
       " \"@AmericanAir thanks I'll look forward to the response.\\n\",\n",
       " '@JetBlue i love this song &lt;3 thanks @JetBlue\\n',\n",
       " '@USAirways Marsha M. at Myrtle Beach is the greatest! She deserves all the respect and praise there is! #ThankYouForEverything\\n',\n",
       " '@USAirways Thank you!!! On our way to get her bag now - thanks to having that number ðŸ˜Š\\n',\n",
       " '@SouthwestAir had a great flight to and from Cabo last week with my family #smoothflight #frequentflyer\\n',\n",
       " \"@SouthwestAir @heavenlychc9 I'd at least enjoy a free cocktail...or two.\\n\",\n",
       " '@JetBlue thanks so much for help Us u r amazing!\\n',\n",
       " '@AmericanAir \"Airport snow removal method #22...\"\\nKeep up the good work folks this is where Cessna\\'s become 747\\'s! http://t.co/oUmC1LrXDN\\n',\n",
       " \"@SouthwestAir Weather keeps slowing us down. Not your fault. This is the 1st time a Southwest flight of mine was Late Flight so I can't complain :)\\n\",\n",
       " '@AmericanAir SFO. Natt (the agent who helped me) really did an awesome job.\\n',\n",
       " '@JetBlue and a HUGE thanks to the crew on flight 1348 who flew in to DCA from SJU Monday night in the snow so we could have a plane!!!\\n',\n",
       " '@USAirways it was customer service like I have never seen before!  Kudos to your organization.\\n',\n",
       " '@SouthwestAir Had a great trip this past week to Vegas for work; and had this pic over the Southwest on Southwest! http://t.co/a3YCFlaLxV\\n',\n",
       " '@SouthwestAir DM sent. Thanks for the help!\\n',\n",
       " '@SouthwestAir Customer Centricity is knowing people #ANAMarketers\\n',\n",
       " '@JetBlue Best airline name ever. Whenever I see it I want to get on their plane to blue skies &amp; sea. (And they DELIVER on that promise)\\n',\n",
       " '@united I JUST ASKED MY BOYFRIEND TO PROM OVER THE LOUDSPEAKER ON FLIGHT 494 HE SAID YES!!!! BEST DAY EVER!!! THANK U SO MUCH!!!!!!\\n',\n",
       " '@AmericanAir  Mad love http://t.co/4ojrSDWPkK NYC-\\n',\n",
       " '@VirginAmerica has getaway deals through May from $59 one-way. Lots of cool cities http://t.co/B2Xi4YG5T8 #CheapFlights #FareCompare\\n',\n",
       " '@JetBlue you guys continue to impress. Your crew @ MCO gate 4helped our family with seat issues. #professional\\n',\n",
       " '@JetBlue Then en route to the airport the rebooked ticket was refunded.\\n',\n",
       " '@AmericanAir thank you we got on a different flight to Chicago.\\n',\n",
       " '@JetBlue thanks so much!\\n',\n",
       " '@AmericanAir @beantownmatty Sounds like a date!\\n',\n",
       " \"@united Thanks - it's very helpful to understand that the reduced price seats that are sold at check-in have priority over the certificates.\\n\",\n",
       " '@AmericanAir Flight attendant #YeseniaHernandez provided excellent service among peculiar conditions throughout the day âœˆ :-)\\n',\n",
       " '@JetBlue Definitely! Lots of announcements and the app is great.\\n',\n",
       " '@united is officially my favorite airline. They have created magic for me all day!!! #friendlyskies #careyon\\n',\n",
       " '@SouthwestAir just added #passbook support to their iOS application! Finally I get to add them to my collection. http://t.co/lEdNoCdQee\\n',\n",
       " '@JetBlue Touchdown JFK! Well done pilots of JetBlue Flight 226! #JetBlueRocks\\n',\n",
       " \"@united I'll stick with my United flight. Thanks though. Effort is much appreciated.\\n\",\n",
       " '@SouthwestAir you are lucky to have people like Annamarie and Norris at BWI. I hope they get recognized for excellent cust. service\\n',\n",
       " \"@USAirways on Sunday! Can't wait! See you then\\n\",\n",
       " '@AmericanAir Absolutely!\\n',\n",
       " '@AmericanAir my boss is :)\\n',\n",
       " '@JetBlue thanks!!\\n',\n",
       " \"@united man I can't wait to book my ticket now! Thanks JP you're a life sabe\\n\",\n",
       " '@AmericanAir if I could fly an md80/dc10 I would be so happy I live that plane so much md80 is love md80 is life.\\n',\n",
       " \"@united please give special thanks to Aaron in Tampa office for helping me for literally two hours! He's amazing. Mission accomplished!\\n\",\n",
       " \"@AmericanAir that's ok thanks for letting me know. Appreciate all the responses.\\n\",\n",
       " '@USAirways landed safely everything worked out.\\n',\n",
       " \"@JetBlue flight booked! Heading out to California with the @WikiPearl team for  @NatProdExpo on March 6-8! Can't wait! #ExpoWest\\n\",\n",
       " '@JetBlue thank you!\\n',\n",
       " '@united stellar customer service. You have earned my business by your attention to detail.\\n',\n",
       " '@united thanks just sent :)\\n',\n",
       " \"@JetBlue thank you! I know the weather in #Boston isn't great. Everyone's tired\\n\",\n",
       " \"@USAirways thank you! I tried that and they said they didn't have it. Anywhere else to try?\\n\",\n",
       " '@USAirways no worries your flight attendant took care of it.\\n',\n",
       " '@JetBlue thank you very very much!! ðŸ’™ðŸ’™\\n',\n",
       " '@SouthwestAir thanks for the reply something is off with the phones becuz after 2 dropped calls at 2 hours on hold I got through on 1 ring\\n',\n",
       " '@USAirways see you on board tomorrow\\n',\n",
       " '@united All flights Cancelled Flighted :( Trip refunded without difficulty staff extremely helpful no complaints! Way to handle bad weather!\\n',\n",
       " '@VirginAmerica Iâ€™m looking forward to watching the Oscars on my flight home tomorrow. I might even get something bubbly to drink! ;)\\n',\n",
       " '@united Thanks for looking into this and for getting back to me via DM. Glad to hear my bag is finally being delivered to me. Thanks again!\\n',\n",
       " '@JetBlue thank you. Appreciate that!!\\n',\n",
       " '@SouthwestAir Yeah we figured it out.  Thanks.\\n',\n",
       " '@JetBlue thank you for incredible customer svc from gate to flight. Mint experience is magic.\\n',\n",
       " \"@USAirways made it!!! Send Bloody Mary's to row 27!!!\\n\",\n",
       " \"@AmericanAir Thanks both airlines said that it is located at AA Detroit. Also was informed that it flew with AA which shouldn't matter.\\n\",\n",
       " '@JetBlue also. Emergency exit seats. 6\\'2\" and that\\'s a huge win.\\n',\n",
       " '@AmericanAir thanks keep me updated just hope I make either of my connections to Killeen Tx\\n',\n",
       " '@united hey awesome!  Thanks for the reply will be filling the form out! @AmericanAir\\n',\n",
       " '@USAirways your pple did a great job w the madness however some of your systems need help. I appreciate the hard work &amp; the push to b better\\n',\n",
       " '@JetBlue Thank you Alicia!  #ExceptionalService\\n',\n",
       " '@SouthwestAir luv my companion pass!\\n',\n",
       " '@AmericanAir versus @JetBlue\\nin Customer Service?\\nWho will win!\\nFor Me @AmericanAir is a convenience to a trip to Cali &lt;3\\n',\n",
       " '@JetBlue I would go to Las Vegas. It is gorgeous and I go there every year and I fly with you guys Vegas is gorgeous &amp; so much to do there.ðŸŒ´\\n',\n",
       " '@united Worked like a charm. Bag was waiting on the carousel when we got to baggage claim. #welldone #goodflight #friendlysky\\n',\n",
       " 'Lovely! RT @JetBlue: Our fleetâ€™s on fleek. http://t.co/Hi6Fl1AX9E\\n',\n",
       " \"@NinaDavuluri We think it's a treat to have you onboard! Enjoy your flight. ðŸ’™\\n\",\n",
       " '@SouthwestAir Sent. Thanks VP!\\n',\n",
       " '@united thank you! ðŸ˜Š\\n',\n",
       " '@AmericanAir This is exactly why ill be flying AA from @Dulles_Airport to Dallas! Only airline I trust!\\n',\n",
       " '@AmericanAir Great seats on this aircraft!\\n',\n",
       " '@AmericanAir Thank you!!!! I will be there to pick her up on time.\\n',\n",
       " '@USAirways\\nGood news we got fixed.\\n',\n",
       " '@JetBlue That makes two of us! Lol #Blushing\\n',\n",
       " '@SouthwestAir lol I already am ! I am a card member as well too lol i enjoy flying with you Guys\\n',\n",
       " \"@VirginAmerica loved it. Can't wait for Monday's return flight... Mostly just to watch the inflight safety video again. #sorrynotsorry\\n\",\n",
       " '@USAirways Thanks! Sent you DM re: baggage issues.\\n',\n",
       " '@SouthwestAir thank you so so much for sending me to LA for #DestinationDragons! Tonight is gonna rockðŸ˜Ž\\n',\n",
       " '@SouthwestAir Thanks! Confirmation number just DMed. Appreciate any help!\\n',\n",
       " \"@AmericanAir Thank you. It's much appreciated. We have been on the plane for 90 min now at the gate.\\n\",\n",
       " '@SouthwestAir truly the best in #customerservice.  If something goes wrong no matter how big or small the issue was they fix it. Thank you\\n',\n",
       " '@SouthwestAir flight 3970 bna-rdu had the most excellent crew today\\n',\n",
       " '@AmericanAir thanks! Flight 2160 today. Great crew!\\n',\n",
       " '@united no worries Your customer service gets a bad wrap but just spoke w agent who saved me huge amounts of time &amp; apologized for yesterday\\n',\n",
       " '@SouthwestAir Thanks. I did go through these motions shortly after my flight yesterday. I wonder how quickly flight attendants are notified.\\n',\n",
       " '@USAirways Thanks. It would be better from the gate agent at C14 in Charlotte boarding flight 1791.\\n',\n",
       " '@united is #ELP Friendly. #flyerfriendly #united #emb145 #elpaso http://t.co/9mEOzBO4xl\\n',\n",
       " '@united have Michelle at T1 ORD train your other staff on how to treat customers. A refreshing pleasure to deal with.\\n',\n",
       " '@VirginAmerica wish I can afford to fly with you next Friday  going back home.. love everything  about your airline\\n',\n",
       " '@SouthwestAir @FortuneMagazine friendliest employees\\n',\n",
       " '@SouthwestAir Awesome staff at the  check in desk! They had a paper airplane race for a SW gift card to keep ppl entertained during delays\\n',\n",
       " '@VirginAmerica thanks for gate checking my baggage on your full flight dfw-lax 883 and giving me early boarding too #sweet\\n',\n",
       " '@USAirways thanks very much! I got thru on the phone &amp; everything is fine. Just love the website &amp; app ! Thanks for working on it!\\n',\n",
       " '@AmericanAir thanks for the update\\n',\n",
       " '@united I will thank you!\\n',\n",
       " '@USAirways thanks for reaching out to me.  My Gold Div no. 2k424j0. My Flights were changed under Confirmation # DNX58V.\\n',\n",
       " '@VirginAmerica completely awesome experience last month BOS-LAS nonstop. Thanks for such an awesome flight and depart time. #VAbeatsJblue\\n',\n",
       " '@JetBlue perfect! Probably need some coffee to stay awake during the night ;)\\n',\n",
       " '@United will you fill it? Yes they will. Thanks! #BringYourOwn @kleankanteen http://t.co/daaa0rqBXW\\n',\n",
       " '@united 441 which also had 1 working WC in coach. Good thing this bird landed ahead of schedule. I have to use the WC stat.\\n',\n",
       " '@JetBlue thank you for always have the most amazing customer service! Bring on The Disney Princess Half Marathon\\n',\n",
       " '@JetBlue I did see that! Working on picking up a trip or two as we type.\\n',\n",
       " '@JetBlue my family and I are excited to see you tooðŸ˜ŠðŸ˜Š\\n',\n",
       " \"@SouthwestAir thank you for your help resolving my problem Shannon ROCKS - even though Rhonda didn't !!\\n\",\n",
       " '@SouthwestAir Thanks to your team for dealing with Flight 1700 to Houston.\\n',\n",
       " '@JetBlue great flight and crew! Flight 51 from BOS to MCO\\n',\n",
       " '@USAirways surprisingly quick response time by you and them. Thanks!\\n',\n",
       " '@united I see. Thanks for explaining.\\n',\n",
       " '@SouthwestAir haha thanks for the explanation\\n',\n",
       " '@SouthwestAir has the best customer service!\\n',\n",
       " '@united Just sent a DM. Thank you for the acknowledgment.\\n',\n",
       " \"@USAirways thank you! It's # 1875 from BWI keep seeing different stats from delayed to awaiting take off to delayed...\\n\",\n",
       " '@SouthwestAir about time! Thank you!\\n',\n",
       " '@JetBlue I want to give a warm thanks to your crew at Logan airport for still getting me to the DC area after Cancelled Flightlations this morning!\\n',\n",
       " '@SouthwestAir Thank you for the prompt response. I will email Late Flightr today.\\n',\n",
       " \"Eliza &amp; I cheated on u @AmericanAir with @AirTahitiNui &amp; it was a lovely flight. But we'll be back! Lots!\\n\",\n",
       " '@united Baggage check in and in flight crew the friendliest ever Flight#417 ogg to Lax !!!\\n',\n",
       " '@USAirways thank you for refunding my bag fee.  I look forward to its return today I hope.\\n',\n",
       " \"@USAirways we haven't departed yet so let's not get too high hopes.  But everything has been on schedule so far\\n\",\n",
       " '@united thanks for all the help! Totally appreciate it and you made it super easy too\\n',\n",
       " '@SouthwestAir loved it!\\n',\n",
       " '@JetBlue OK thank you.\\n',\n",
       " \"@SouthwestAir Thanks. I'll keep checking. I'm trying to book our first Disney World vacation.\\n\",\n",
       " \"@SouthwestAir Glad to know I'll be flying the luv airline tomorrow ;)\\n\",\n",
       " '@JetBlue great flight! Great view! :-) http://t.co/Yxn00pnOav\\n',\n",
       " '@JetBlue nothing but praise for you helping our lady make her flight to CHS tonight!  #impressed\\n',\n",
       " '@USAirways i hope i get the opportunity to join the team with this job opening!\\n',\n",
       " \"@JetBlue I'll pass along the advice. You guys rock!!\\n\",\n",
       " '@united thanks! Everything a-ok now.\\n',\n",
       " '@united Gate Agent Alavera is amazing\\n',\n",
       " '@SouthwestAir telling my Fam in Vegas now. :)\\n',\n",
       " '@SouthwestAir Landed in Nashville! Thanks for taking care of us! http://t.co/RYXbPLgMnK\\n',\n",
       " \"@SouthwestAir been with my GF for 2.5yrs she's from SF &amp; I live in Tulsa. SWA always takes me there to see my love! #SouthwestLuvSweeps\\n\",\n",
       " '@SouthwestAir @SAMoore10 Thank you for your kind response.  The acknowledgement and apology go a long way! #southwestrocks\\n',\n",
       " '@VirginAmerica another perfect flight.   How come on your planes  the sun visors can stay down?  Other carriers make you raise them?\\n',\n",
       " '@united thnx\\n',\n",
       " '@SouthwestAir thanks so much for making my night ðŸ˜€ cannot wait for my trip next week! http://t.co/NbZ45jCd1r\\n',\n",
       " '@AmericanAir 1138 got us to LGA safely. Thanks for taking the time to make the plane safe before flying!\\n',\n",
       " '@JetBlue had a great experience working with Glenn Coles at Buffalo-Niagara Airport!! Top notch employee\\n',\n",
       " '@united thanks for the epic service on 863- always a pleasure- outstanding crew http://t.co/trqlpeinzW\\n',\n",
       " '@AmericanAir Not necessary.  I am confident the excellent in-flight staff will make the appropriate report.\\n',\n",
       " '@JetBlue thanks...\\n',\n",
       " '@VirginAmerica cool picture of another VirginAmerica plane off our wing. What a site! http://t.co/5B2agFd8c4\\n',\n",
       " '@SouthwestAir just got a call apologizing personally for the long waits last week trying to rebook flights. Class act. I appreciate that!\\n',\n",
       " \"@JetBlue you don't remember our date Monday night back to NYC? #heartbroken\\n\",\n",
       " '@SouthwestAir much respect!\\n',\n",
       " '@JetBlue currently dancing in the terminal. love Stevie!\\n',\n",
       " '@united thanks for the re-upgrade to 1st class. It may be a 45 min flight but it is appreciated.\\n',\n",
       " \"@southwestair #fattuesday Great job celebrating #mardigras today at Atlanta Airport. Another reason I'm nuts for you! http://t.co/8WBzOrRn3C\\n\",\n",
       " '@united Cool. Thank you.\\n',\n",
       " '@SouthwestAir thank you will do\\n',\n",
       " '@AmericanAir no worries even though I was talking about seat assignment :)\\n',\n",
       " '@SouthwestAir its all good. flight eventually took off and landed safely. oh and I got the free cup o wine. thx\\n',\n",
       " '@united that would help! or how about integrate it into the App so I can just \"activate\" it and surf...\\n',\n",
       " '@JetBlue your customer service agent Bonnie is amazing on the phone she deserves a promotion!!!\\n',\n",
       " '@AmericanAir 1) I was on 1610 today to YYZ. I had a bit of a bag issue that was cleared up beautifully. Thank you to all of the check in\\n',\n",
       " '@VirginAmerica I love the hipster innovation. You are a feel good brand.\\n',\n",
       " \"@united all good man it isn't your fault that plane is having maintenance issues\\n\",\n",
       " '@united thank you so much that helps a ton. Whoever is on this Twitter acct today deserves a handshake and a hot chocoLate Flight. #problemsolvers\\n',\n",
       " '@AmericanAir My pleasure next AA flight - this Wednesday to Milan Italy for @MIDOExhibition -- See you then! :)\\n',\n",
       " '@united great to hear Thankyou so much. Greatly appreciate your replies. Feel much more settled now.\\n',\n",
       " '@VirginAmerica wifi AND better seating.\\n',\n",
       " '@USAirways - Huge props to Parizad at checkin in Sacramento for her help on Friday to get 3 of us home when other airlines were delayed\\n',\n",
       " '@VirginAmerica this is great news!  America could start flights to Hawaii by end of year http://t.co/r8p2Zy3fe4 via @Pacificbiznews\\n',\n",
       " '@JetBlue Thanks for the instant reply and for still doing first bag free (so important)!\\n',\n",
       " '@JetBlue is amazing. Had a short delay. They gave me $150 credit! It was literally pretty much my fault I missed the flight.\\n',\n",
       " '@SouthwestAir give this guy a raise....great start to flight from AZ to MKE..\\n',\n",
       " \"@JetBlue Thanks for the quick reply! Just wanted to make sure it wasn't just my account :)\\n\",\n",
       " 'Thank you @united for your prompt assistance.\\n',\n",
       " '@USAirways I totally understand the weather. Just frustrated. Thanks!\\n',\n",
       " '@virginamerica awesome deals DAL-AUS for only $39 each way! https://t.co/xCVQXYkg49\\n',\n",
       " '@SouthwestAir AMAZING c/s today by SW thank you SO very much. This is the reason we fly you #southwest\\n',\n",
       " '@JetBlue mission accomplished: gave @paulgordonbrown  a hug http://t.co/LT1pYKfvRq\\n',\n",
       " '@SouthwestAir beautiful view flying into San Jose CA this evening http://t.co/SxVaGbRTlI\\n',\n",
       " '@AmericanAir No worries at all. Yâ€™all have a good one!!\\n',\n",
       " '@AmericanAir @maryella_green despite the inconvenience the situation was handled quickly and we appreciate it very much!\\n',\n",
       " '@united I was protected on that flight by gate agent Kerry at LAS. She also did an excellent job getting me to my destination today. Thanks!\\n',\n",
       " '@USAirways customer service at its best! Rachel S.  took great care of us at the PHX airport. http://t.co/HG7vEqhGHy\\n',\n",
       " '@JetBlue thanks!\\n',\n",
       " '@SouthwestAir Flight 1700. (PHX TO LAX) Wheels stop.  Glad to be home!  Thanks to the professionals both up front and in the cabin!!!\\n',\n",
       " '@JetBlue @CinziannaP thank you! I like the quick response on Twitter!\\n',\n",
       " '@SouthwestAir I did. Thank you.\\n',\n",
       " '@AmericanAir @contactcej thanks!\\n',\n",
       " '@SouthwestAir show me some love and a companion flight~please and thank you!\\n',\n",
       " '@JetBlue Amazingly Awesome customer service from your reservation agents tonight. Helping correct a mistake. I so love this airline. :)\\n']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "id": "3ywJQ5pyNr8b",
    "outputId": "702c400d-4914-4da6-99ee-61ab141659d2"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-bb0edcddfb48>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    if stemmed == 1:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#Checking Stemming/ Not Stemming data\n",
    "for i in range(0, len(X)):\n",
    "    X[i] = cleaningStemmed(X[i])\n",
    "\n",
    "for i in range(0, len(X)):\n",
    "    X[i] = clean(X[i])\n",
    "\n",
    "# Creating vocabulary list\n",
    "vocab = X[0]\n",
    "  for i in range(1, len(X)):\n",
    "  vocab.extend(X[i])\n",
    "vocab = sorted(set(vocab))\n",
    "\n",
    "    row = len(X)\n",
    "    col = len(vocab)\n",
    "\n",
    "    dict_vocab = {}\n",
    "    for i, j in enumerate(vocab):\n",
    "        dict_vocab[j] = i\n",
    "    trainVector = np.zeros((row, col), dtype=np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-OhpFRejNr72"
   },
   "source": [
    "### b) Extract Features: Convert documents to vectors using tf-idf representation. Do not use the existing tf-idf calculation library.\n",
    "\n",
    "#Nina: copy/paste and test from homework1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "sm5oYAQ05aOc"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainVector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-67b469d6ee32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# Vectorizing the trainset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mtrainVector\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainVector\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdict_vocab\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvectorType\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainVector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mtrainVector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainVector\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainVector' is not defined"
     ]
    }
   ],
   "source": [
    "# Vectorizing based user input\n",
    "def vectorizer(X,vectorArr,dict_vocab,vectorType,row,col):\n",
    "\n",
    "    if (vectorType==1):\n",
    "        for i in range(0, len(X)):\n",
    "            for j in X[i]:\n",
    "                if j in dict_vocab:\n",
    "                    vectorArr[i, dict_vocab[j]] += 1\n",
    "\n",
    "\n",
    "        idf= np.zeros((row, col), dtype=np.int64)\n",
    "        for i in range(0,len(vectorArr)):\n",
    "            for j in range(0,col):\n",
    "                if vectorArr[i][j] > 0:\n",
    "                    idf[i][j]= math.log10(row / float(vectorArr[i][j]))\n",
    "\n",
    "                else:\n",
    "                    idf[i][j]=0\n",
    "        vectorArr=np.multiply(vectorArr, idf)\n",
    "\n",
    "    return vectorArr\n",
    "\n",
    "\n",
    "# Vectorizing the trainset\n",
    "trainVector=vectorizer(X,trainVector,dict_vocab,vectorType,row,col)\n",
    "m, n = trainVector.shape\n",
    "trainVector = np.concatenate([np.ones((m, 1)), trainVector], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NmWanpP6hh_6"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKIeP92WNr78"
   },
   "source": [
    "### c) Training: Note that if you want to experiment with different stemmers or other aspects of the input features, you must do so on the training set, either through cross-validation or by setting a development set from the get-go. You must not do such preliminary evaluations on test data. Once you have finalized your system, you are ready to evaluate the test data. You can ignore any words that appear in the test set but not the training set.\n",
    "\n",
    "# Anh(lead) and Nina(assist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "93jIWyNk5urB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTZEQcr65x3k"
   },
   "source": [
    "### d) Build and train a feed forward neural network: Build your FFNN with 2 layers with hidden vector size 20. Initialize the weights with random numbers. Use mean squared error as your loss function, sigmoid as the activation function. You can start training with a learning rate of 0.0001. If you would like to tune any parameters, you must do so using cross-validation on the training data only. Once you have finalized your system, you are ready to evaluate the test data.\n",
    "\n",
    "#Nina(lead) and Anh(assist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QkCdRUjdiHWg"
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "learning_rate = 0.0001\n",
    "weights = np.random.rand(2,1)\n",
    "bias = np.random.rand(1)\n",
    "\n",
    "\n",
    "#activation function\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1.0+np.exp(-x))\n",
    "\n",
    "#derivative of the sigmoid function\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1poH-oGMiHZo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U06_T8IViHcq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GqFvhn8WNr8F"
   },
   "source": [
    "### e) Evaluation: Compute the most likely class for each review in the test set using each of the combinations of stemming + tf-idf, no-stemming + tf-idf. Compute and report accuracy with confusion matrix on a .txt or .log file.\n",
    "\n",
    "## Anh: Copy/paste and test from homework1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "653QdEwW5-Vr"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHG2Pm5mS-_2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hujXoKxjNr8I"
   },
   "source": [
    "## Feed forward neural network for language modelling\n",
    "## Yitong and Shinoj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cukIuNVXNr8J"
   },
   "source": [
    "### a) Pre-processing: Read the data word by word from a “train/positive”. Remove any markup tags, e.g., HTML tags, from the data. Lower case capitalized words (i.e., starts with a capital letter) but not all capital words (e.g., USA). Do not remove stopwords. Tokenize at white space and also at each punctuation. Consider emoticons in this process. You can use an emoticon tokenizer, if you so choose. If yes, specify which one.\n",
    "\n",
    "## Copy/paste and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ZjLdRz8i7QQF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import collections\n",
    "import re\n",
    "import numpy as np\n",
    "import time\n",
    "import xml\n",
    "import pandas as pd\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import nltk\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#captures runtime\n",
    "start_time = time.time()\n",
    "\n",
    "def normalize_case(s):    \n",
    "    '''\n",
    "    Paramaeter: Word to be normalized\n",
    "    Converts words with capitalized first letters in to lower case.\n",
    "    '''\n",
    "    if(not s.isupper()):\n",
    "        return s.lower()\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "def remove_tags(s):\n",
    "    '''\n",
    "    Paramaeter: Word to be normalized\n",
    "    Removes HTML tags\n",
    "    '''\n",
    "    s = re.sub(r'[^\\w\\s]', '', s)\n",
    "    return s\n",
    "\n",
    "def Remove(duplicate): \n",
    "    '''\n",
    "    Calculate the unique words in a list\n",
    "    '''\n",
    "    final_list = [] \n",
    "    for num in duplicate: \n",
    "        if num not in final_list: \n",
    "            final_list.append(num) \n",
    "    return final_list \n",
    "\n",
    "def count_words(rootdir):\n",
    "    '''\n",
    "    Parameter: root directory\n",
    "\n",
    "    The funtion collects the training files. Tokenizes text into words. Creates stemmed vocabulary and\n",
    "    Counts the the occurance of each word in each class(positve and negative).\n",
    "    '''\n",
    "    vocab = []\n",
    "\n",
    "    bigram = []\n",
    "    cleaned_document = []\n",
    "    # For each directory in the path\n",
    "    z = 0\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        # For each file in the directory\n",
    "        for file in files:\n",
    "            z = z + 1\n",
    "            if (z > 1180):\n",
    "                break\n",
    "            cleaned_document = []\n",
    "            f = open(rootdir + file, 'r',encoding='utf-8')  # use the absolute URL of the file\n",
    "            lines = f.readlines()\n",
    "            # For each line in the file\n",
    "            for line in lines:\n",
    "                document = word_tokenize(line)\n",
    "                for i in range(0, len(document)):\n",
    "                    # Normalize case for the word\n",
    "                    document[i] = normalize_case(document[i])\n",
    "                    # Remove HTML tags\n",
    "                    document[i] = remove_tags(document[i])\n",
    "                    if (document[i] != ''):\n",
    "                        cleaned_document.append(document[i])\n",
    "                        vocab.append(document[i])\n",
    "\n",
    "            # Store as bigrams\n",
    "            bigram.extend(list(nltk.bigrams(cleaned_document)))\n",
    "    \n",
    "    uni_vocab=Remove(vocab)        \n",
    "    # return positive bigram and vocabulary\n",
    "    return bigram, uni_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vmmNjQTNr8P"
   },
   "source": [
    "### b) Construct your n-grams: Create positive n-gram samples by collecting all pairs of adjacent tokens. Create 2 negative samples for each positive sample by keeping the first word the same as the positive sample, but randomly sampling the rest of the corpus for the second word. The second word can be any word in the corpus except for the first word itself.\n",
    "\n",
    "#Shinoj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "AaxDV56P7OQJ"
   },
   "outputs": [],
   "source": [
    "def make_bigrams(rootdir):\n",
    "    '''\n",
    "    The function collects positive bigrams, creates negative bigrams from them\n",
    "    and stores them in a csv file\n",
    "    '''\n",
    "    pos_bigram, vocab = count_words(rootdir)\n",
    "\n",
    "    # Randomly creates 2 negative bigrams for each positive bigrams\n",
    "    neg_bigram = []\n",
    "    for bigram in pos_bigram:\n",
    "        rand_neg = (bigram[0], random.choice(vocab))\n",
    "        neg_bigram.append(rand_neg)\n",
    "        rand_neg = (bigram[0], random.choice(vocab))\n",
    "        neg_bigram.append(rand_neg)\n",
    "\n",
    "    # Combines the bigrams and stores it in a csv\n",
    "    pos_df = pd.DataFrame(pos_bigram, columns=['first_word', 'second_word'])\n",
    "    pos_df['tag'] = \"pos\"\n",
    "\n",
    "    neg_df = pd.DataFrame(neg_bigram, columns=['first_word', 'second_word'])\n",
    "    neg_df['tag'] = \"neg\"\n",
    "\n",
    "    df = pos_df.append(neg_df, ignore_index=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fg8ooaQeNr8X"
   },
   "source": [
    "### c) Build and train a feed forward neural network: Build your FFNN with 2 layers with hidden vector size 20. Initialize the weights with random numbers. Use mean squared error as your loss function, sigmoid as the activation function. You can start training with a learning rate of 0.0001 or 0.00001. If you would like to tune any parameters, you must do so using cross-validation on the training data only. Once you have finalized your system, you are ready to evaluate the test data\n",
    "\n",
    "## Yitong and Shinoj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bigram with labels\n",
    "df=make_bigrams(\"./train/positive/\")\n",
    "\n",
    "# Extracting Input and Output variables\n",
    "y = df['tag']\n",
    "X = df['first_word'] + ' ' + df['second_word']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        pos\n",
       "1        pos\n",
       "2        pos\n",
       "3        pos\n",
       "4        pos\n",
       "        ... \n",
       "47077    neg\n",
       "47078    neg\n",
       "47079    neg\n",
       "47080    neg\n",
       "47081    neg\n",
       "Name: tag, Length: 47082, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "-L6zP34L7GOv"
   },
   "outputs": [],
   "source": [
    "# Converting text data into vectorized format(Count Vectorizer)\n",
    "X1 = CountVectorizer()\n",
    "X1.fit(X)\n",
    "data = X1.transform(X)\n",
    "data_array = data.toarray() # input\n",
    "\n",
    "# Label Encoding the data\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "Y = le.transform(y) # labeled output\n",
    "labels=Y.reshape(data_array.shape[0],1)\n",
    "\n",
    "# Feed forward neural network model\n",
    "# the biases are ignored in this code\n",
    "\n",
    "hidden_size = 20 # hidden layer size\n",
    "np.random.seed(42)\n",
    "weights1 = np.random.rand(data_array.shape[1],hidden_size)\n",
    "weights2 = np.random.rand(hidden_size,1) \n",
    "lr = 0.00001\n",
    "train, test, y_train, y_test = train_test_split(data_array, labels, test_size=0.3, random_state=1000)\n",
    "labels=y_train\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_der(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n",
    "\n",
    "for epoch in range(200): # recommend setting epoch to 10 to quickly run the code. Setting epoch to 2000 when training the weight\n",
    "    inputs = train\n",
    "\n",
    "    # feedforward layer 1\n",
    "    layer1 = sigmoid(np.dot(inputs, weights1))\n",
    "    # feedforward output layer\n",
    "    output = sigmoid(np.dot(layer1, weights2))\n",
    "    \n",
    "    # use 0.5 as a threshold. If less than 0.5, assigns label 0; if more than 0.5, assigns label 1\n",
    "    for i in range(0,len(output)):\n",
    "        if (output[i] <= 0.5):\n",
    "            output[i] = 0\n",
    "        else:\n",
    "            output[i] = 1\n",
    "\n",
    "    # backpropagation \n",
    "    # calculate errors\n",
    "    # error = output - labels\n",
    "    # print(error.sum())\n",
    "    \n",
    "    # application of the chain rule to find derivative of the loss function with respect to weights2 and weights1\n",
    "    # the derivative mse (1/n)(labels - output)^2 is 2/n [(labels - output)]. Here, 2/n is constant and therefore can be ignored\n",
    "    weights2_delta = (output - labels) * sigmoid_der(output)   \n",
    "    weights1_delta = np.dot((output - labels) * sigmoid_der(output), weights2.T) * sigmoid_der(layer1)    \n",
    "    \n",
    "    # update weights1 and weights2\n",
    "    d_weights2 = np.dot(layer1.T, weights2_delta) \n",
    "    d_weights1 = np.dot(inputs.T, weights1_delta)\n",
    "    \n",
    "    weights1 -= lr * d_weights1\n",
    "    weights2 -= lr * d_weights2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQ4PdpIxNr8Z"
   },
   "source": [
    "### d) Evaluate: Compute the most likely class for each n-gram in the test set. Use the test set in the “test/positive” folders. Save your results in a.txt or .log file.\n",
    "\n",
    "## Yitong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "kpNlkYvX7EsZ"
   },
   "outputs": [],
   "source": [
    "# evaluate\n",
    "# use the trained model to predict\n",
    "layer1 = sigmoid(np.dot(test, weights1))\n",
    "output = sigmoid(np.dot(layer1, weights2))\n",
    "# use 0.5 as a threshold. If less than 0.5, assigns label 0; if more than 0.5, assigns label 1\n",
    "for i in range(0,len(output)):\n",
    "    if (output[i] <= 0.5):\n",
    "        output[i] = 0\n",
    "    else:\n",
    "        output[i] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmqncDV3AKiG"
   },
   "source": [
    "### e) Evaluation Methods: Compute and report accuracy. Save your output and accuracy in a .txt or .log file.\n",
    "\n",
    "## Yitong\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "0Ab-t1sw7B_J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36658407079646016\n"
     ]
    }
   ],
   "source": [
    "error = output - y_test # is error is non zero, then it is not accurately predicted\n",
    "z=0\n",
    "for i in range(0,len(error)):\n",
    "    if (error[i] == 0):\n",
    "        z=z+1\n",
    "\n",
    "accuracy = z/len(test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AIT726_Assignment_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
